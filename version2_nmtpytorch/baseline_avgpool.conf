[train]
seed: 0
model_type: MultimodalNMT
patience: 10
max_epochs: 100
eval_freq: 0
eval_metrics: rouge,meteor,bleu,loss
eval_beam: 12
eval_batch_size: 32
save_best_metrics: True
eval_max_len: 100
n_checkpoints: 0
l2_reg: 1e-05
lr_decay: plateau
lr_decay_revert: False
lr_decay_factor: 0.5
lr_decay_patience: 2
gclip: 1
optimizer: adam
lr: 0.0004
batch_size: 64
save_path: checkpoints
tensorboard_dir: ${save_path}/tb_dir

[model]
att_type: mlp
att_bottleneck: hid
enc_dim: 320
dec_dim: 320
emb_dim: 200
dropout_emb: 0.4
dropout_ctx: 0.5
dropout_out: 0.5
n_encoders: 2
tied_emb: 2way
bucket_by: findings
max_len: None

sampler_type: approximate
sched_sampling: 0
dec_init: zero
bos_type: emb

feat_fusion: encdecinit
feat_dim: 2048
feat_activ: tanh
direction: findings:Text, feats:Numpy -> impression:Text

[data]
tok_root: preprocessing/out_nmtpytorch
vocab_root: preprocessing/out_nmtpytorch
feats_root: preprocessing/out_nmtpytorch

train_set: {'findings': '${tok_root}/train.findings.tok',
            'feats': '${feats_root}/train_avgpool.npy',
            'impression': '${tok_root}/train.impression'}

val_set: {'findings': '${tok_root}/dev.findings',
          'feats': '${feats_root}/dev_avgpool.npy',
          'impression': '${tok_root}/dev.impression'}

[vocabulary]
findings: ${data:vocab_root}/train.vocab.findings
impression: ${data:vocab_root}/train.vocab.impression